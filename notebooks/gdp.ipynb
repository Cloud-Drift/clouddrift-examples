{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6426c30b-df03-46a9-8fb7-57ddf404683e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Working with the hourly Global Drifter Program (GDP) data\n",
    "\n",
    "In this Notebook, we use the [hourly data](https://www.aoml.noaa.gov/phod/gdp/hourly_data.php) from the [NOAA Global Drifter Program](https://www.aoml.noaa.gov/global-drifter-program/) to illustrate the steps to preprocess a Lagrangian dataset into a `RaggedArray` format that can be then emitted as `xarray.Dataset` or `awkward.Array` instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4c013-74b6-4444-828c-b74d6231141a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import the `RaggedArray` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b205ff8-500a-486a-b6e5-1ca835f463d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clouddrift import RaggedArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebd53c4-b227-4168-b5be-afbebf06f61b",
   "metadata": {},
   "source": [
    "The `RaggedArray` class can be initialized with a series of `dict`s matching the name of the variables of the original data with the ragged representation of the data and their respectives attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edd40a-998d-45eb-a3f9-0db5cd842645",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RaggedArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958fa781-ba38-4b47-9038-c0b9442f81ff",
   "metadata": {},
   "source": [
    "The length of the variables in the dataset is either equal to the number of trajectories (`nb_traj`) or the number of observations (`obs`) derived along the trajectories. \n",
    "\n",
    "The first three dictionnaries, `coords`, `metadata`, and `data`, match the variable names for coordinates variables, metatadata variables, and data variables, respectively, with the ragged representation of the data.\n",
    "\n",
    "- The coordinates are mandatory variables (length `obs`) for the ragged array to be used with the library and are always `time`, `lon`, `lat`, and `ids`. \n",
    "- The metadata variables (length `nb_traj`) are constant values associated with a single trajectory such as the length of the observations (`rowsize`), the deployment information (`deploy_lon`, `deploy_lat`, `deploy_date`), the type of buoys (`typebuoy`), etc.\n",
    "- The data variables (length `obs`) are quantity derived along the trajectories such as velocity component (`ve`, `vn`), the sea surface temperature and its uncertainty (`sst`, `err_sst`), the drogue presence flag (`drogue_status`), etc.\n",
    "\n",
    "The last two dictionaries, `attrs_global` and `attrs_variables`, are optional and contain the attributes related to the dataset and each variable, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b325e69-44b4-4c18-b4d1-d506f5cd56b2",
   "metadata": {},
   "source": [
    "## The `RaggedArray.from_files()` method\n",
    "\n",
    "This method is available to initialize a `RaggedArray` instance from a series of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46341618-3ed0-4bef-9322-be0239a2477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RaggedArray.from_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6693b-639a-458b-a269-040cf764961c",
   "metadata": {},
   "source": [
    "This method was inspired by the [Pangeo Forge](https://pangeo-forge.readthedocs.io/en/latest/) project which aims at easing the extraction of data from traditional data archives and deposition in cloud object storage. For our `RaggedArray.from_files()` method, the different parameters are:\n",
    "\n",
    "- `indices`: a list of indices (or identification numbers) that will be iterated over to concatenate the files into the `RaggedArray` instance;\n",
    "- `preprocess_func`: A preprocessing function with the following signature:\n",
    "    - `Signature: preprocess_func(index: int) -> xarray.core.dataset.Dataset`, where the index parameter is an identifier of a trajectory, e.g. the identification number of an Argo float) and returns an [xarray Dataset](https://docs.xarray.dev/en/latest/generated/xarray.Dataset.html). \n",
    "- `vars_coords`: a dictionary mapping the mandatory coordinates list to the name of those variables in the dataset, e.g.\n",
    "    `coords = {'ids': 'number', 'time': 't', 'lon': 'longitude', 'lat': 'latitude'}`\n",
    "- `vars_meta`: an optional list of variable names containing metadata information about the trajectory (size: 1 per trajectory)\n",
    "- `vars_data`: an optional list of variable names containing the data along the trajectory (size: number of observations per trajectory)\n",
    "- `rowsize_func`: an optional function that returns directly the number of observation of a trajectory (`Signature: rowsize_func(index: int) -> int`)\n",
    "\n",
    "Because every dataset is unique, the preprocessing function is used to perform operations such as: formatting the date and time, changing the type of the variables, modifying the metadata, and similar. The class also needs to initially calculate the sum of all observations to allocate memory. To speed up this process where a lot of preprocessing is needed, it is possible to provide a second function `rowsize_func`, that returns directly the number of observations of a trajectory (`Signature: rowsize_func(index: int) -> int`). By default, this operation is performed using `lambda i: preprocess_func(i).dims['obs']`. \n",
    "\n",
    "We provide preprocessing function for different datasets in the `data/` folder (`gdp.py`, `gdp6h.py`, `parcels.py`, etc.) and those can serve as a guide to defined a new set of functions for another dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aded949-7d07-47fd-b184-50574c2600ba",
   "metadata": {},
   "source": [
    "# Dataset-specific functions\n",
    "The `gdp.py` module contains a number of specific functions for the current GDP files, including:\n",
    "- `gdp.preprocess`: applies preprocessing routine and returned a `xarray.Dataset` for a specific trajectory \n",
    "- `gdp.download`: fetches NetCDF files from the GDP FTP server\n",
    "- `gdp.rowsize [Optional]`: returns the dimension of a specific trajectory to speed up the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa29c2-5cfa-4ca7-ada3-7c3a6ec3b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from data import gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a0c03-fcb3-4131-af3c-e6e7bea4e833",
   "metadata": {},
   "source": [
    "## Download the GDP data\n",
    "\n",
    "The `gdp.download` function will store the raw dataset into the `data/raw/gdp-v2.00/` folder (specified in the `gdp.py` module). By default `download()` will download the complete GPD dataset (containing 17,324 files for versions 1.04c and 2.00) from the AOML repository ([link](https://www.aoml.noaa.gov/ftp/pub/phod/lumpkin/hourly/v2.00/netcdf/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff938826-a6af-4e18-b8b1-39d236c92608",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(gdp.download)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d977de-6162-4f63-b576-e9377d1d4f3e",
   "metadata": {},
   "source": [
    "With this function, it is also possible to retrieve a subset from a `drifter_ids` list or specified an integer `n_random_id` to randomly retrieve `n` trajectories. If both arguments are given, the function downloads `n_random_id` out of the list `drifter_ids`. The function returns the list of `drifters_ids` that was downloaded, and can be passed to create the ragged array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ca507-0dab-4d84-bf9b-665fcb860755",
   "metadata": {},
   "outputs": [],
   "source": [
    "drifter_ids = gdp.download(n_random_id=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f383e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drifter_ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b92178",
   "metadata": {},
   "source": [
    "## Create the `RaggedArray` instance\n",
    "\n",
    "Once the data are downloaded, the *RaggedArray* object can be created and archived as a NetCDF file or a parquet file. In addition, the ragged array can be converted to an [xarray Dataset](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.html) or an [Awkward Array](https://awkward-array.readthedocs.io/en/stable/_auto/ak.Array.html) in order to conduct analyses.\n",
    "\n",
    "Before we do that, we must first define the dataset-specific coordinates, data, and metadata information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59137333-eed9-406f-8af2-e3a782fad210",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\n",
    "    'ids': 'ids',\n",
    "    'time': 'time',\n",
    "    'lon': 'longitude', # or alternatively lon360\n",
    "    'lat': 'latitude'\n",
    "}\n",
    "metadata = [\n",
    "    'ID',\n",
    "    'rowsize', \n",
    "    'WMO',\n",
    "    'expno',\n",
    "    'deploy_date',\n",
    "    'deploy_lat',\n",
    "    'deploy_lon',\n",
    "    'end_date',\n",
    "    'end_lat',\n",
    "    'end_lon',\n",
    "    'drogue_lost_date',\n",
    "    'typedeath',\n",
    "    'typebuoy',\n",
    "    'location_type',\n",
    "    'DeployingShip',\n",
    "    'DeploymentStatus',\n",
    "    'BuoyTypeManufacturer',\n",
    "    'BuoyTypeSensorArray',\n",
    "    'CurrentProgram',\n",
    "    'PurchaserFunding',\n",
    "    'SensorUpgrade',\n",
    "    'Transmissions',\n",
    "    'DeployingCountry',\n",
    "    'DeploymentComments',\n",
    "    'ManufactureYear',\n",
    "    'ManufactureMonth',\n",
    "    'ManufactureSensorType',\n",
    "    'ManufactureVoltage',\n",
    "    'FloatDiameter',\n",
    "    'SubsfcFloatPresence',\n",
    "    'DrogueType',\n",
    "    'DrogueLength',\n",
    "    'DrogueBallast',\n",
    "    'DragAreaAboveDrogue',\n",
    "    'DragAreaOfDrogue',\n",
    "    'DragAreaRatio',\n",
    "    'DrogueCenterDepth',\n",
    "    'DrogueDetectSensor'\n",
    "]\n",
    "data = [\n",
    "    've',\n",
    "    'vn',\n",
    "    'err_lat',\n",
    "    'err_lon',\n",
    "    'err_ve',\n",
    "    'err_vn',\n",
    "    'gap',\n",
    "    'sst',\n",
    "    'sst1',\n",
    "    'sst2',\n",
    "    'err_sst',\n",
    "    'err_sst1',\n",
    "    'err_sst2',\n",
    "    'flg_sst',\n",
    "    'flg_sst1',\n",
    "    'flg_sst2',\n",
    "    'drogue_status'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bec854",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = RaggedArray.from_files(\n",
    "    drifter_ids,\n",
    "    gdp.preprocess,\n",
    "    coords, \n",
    "    metadata,\n",
    "    data,\n",
    "    rowsize_func=gdp.rowsize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00705eef-eb9b-4cdd-958d-e9afb832e7f0",
   "metadata": {},
   "source": [
    "## Export to data files\n",
    "\n",
    "Currently, the library supports exporting the `RaggedArray` instance to NetCDF and Apache Parquet file formats.\n",
    "\n",
    "### NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e377c2-2fba-4378-8c77-4f6747fa51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.to_netcdf('../data/process/gdp_v2.00.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bedf9",
   "metadata": {},
   "source": [
    "### Apache Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1df311",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.to_parquet('../data/process/gdp_v2.00.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae94b4a-9be6-42b0-8271-0afd183b3057",
   "metadata": {},
   "source": [
    "## Import from data files\n",
    "\n",
    "As with exporting to files, we can import a `RaggedArray` instance from a NetCDF or Apache Parquet files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32b870",
   "metadata": {},
   "source": [
    "### NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = RaggedArray.from_netcdf('../data/process/gdp_v2.00.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285992c9",
   "metadata": {},
   "source": [
    "### Apache Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b284ec72-2307-4022-9a69-801f09dc6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = RaggedArray.from_parquet('../data/process/gdp_v2.00.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95816311-3e8a-4a83-b1ab-bcca807efe80",
   "metadata": {},
   "source": [
    "## Converting to data structures for analysis\n",
    "\n",
    "Typically, you would not do your data analysis directly on a `RaggedArray` instance.\n",
    "Instead, you first convert it to a data structure that is geared for data analysis and exploratory science.\n",
    "Currently, the library supports Xarray Dataset and Awkward Array structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c410201",
   "metadata": {},
   "source": [
    "### Xarray Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ac3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ra.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e934d",
   "metadata": {},
   "source": [
    "Now we have our GDP dataset as an Xarray Dataset while also being optimized for memory.\n",
    "Let's see what's inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcaaa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ec5f5",
   "metadata": {},
   "source": [
    "\n",
    "Time, longitude, and latitude arrays are 1-dimensional and are effectively a concatenated list of drifter trajectories. The `ids` array can be used to mask (subset) a specific drifter. Let's make a trajectory map by looping over all the trajectories and plotting them one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf572db-3cd9-493e-8fa7-a0894ac77779",
   "metadata": {},
   "outputs": [],
   "source": [
    "for drifter_id in drifter_ids:\n",
    "    this_drifter = ds.ids == drifter_id\n",
    "    plt.plot(ds.lon[this_drifter], ds.lat[this_drifter], linestyle='', marker='.', ms=0.1)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('100 random trajectories from the hourly GDP dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f82b50-3562-4509-b084-fe2a088fd940",
   "metadata": {},
   "source": [
    "You may find that the method above is relatively slow to plot for a large number of trajectories. Alternatively, we can construct an index variable that indexes the beginning of each trajectory in the ragged arrays (with index `0` for the first trajectory). We first need to import the `numpy` package to conduct some mathematical operations to calculate that index variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7e6d1-f192-4c6a-bf7c-83f484000273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd106b5d-d1ae-4ca3-8384-751cc54b7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_idx = np.insert(np.cumsum(ds.rowsize.values),0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c841e235-b034-4e13-ba94-94c9fe745d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(drifter_ids)):\n",
    "    plt.plot(ds.lon[slice(traj_idx[j],traj_idx[j+1])], ds.lat[slice(traj_idx[j],traj_idx[j+1])], linestyle='', marker='.', ms=0.1)    \n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('100 random trajectories from the hourly GDP dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a38f5-93e3-41ff-a711-4302ad51b304",
   "metadata": {},
   "source": [
    "### Awkward Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334d731-4bfd-4e29-9196-bd68953df007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ra.to_awkward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228d0e6",
   "metadata": {},
   "source": [
    "With an awkward array, there is no need to define an index variable as for an xarray Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(drifter_ids)):\n",
    "    plt.plot(ds.obs['lon'][n], ds.obs['lat'][n], linestyle='', marker='.', ms=0.1)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('100 random trajectories from the hourly GDP dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
